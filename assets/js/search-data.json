{
  
    
        "post0": {
            "title": "Title",
            "content": "A look at Fastai&#39;s &#39;L&#39; Data Structure . toc: true | branch: master | badges: true | comments: true | author: Harish Vadlamani | categories: [fastai, data structures] | . . The actual documentation for L can be found here. . L is defined in fastcore repo and generated from the &#39;01_foundation.ipynb&#39; notebook. . . Imports . from fastcore.imports import * from fastai2.vision.all import * . What is the &#39;L&#39; data structure? . I gave a brief intro to L when building an image classifier using Fastai V2 in my previous blog which you can find here . L is a special Fastai datastructure made specifically to handle with ease the model building in the library. Since, it forms the basic foundation to using the library, it&#39;s worth digging deeper into its functionalities. . It&#39;s worth noting that when trying to dig deeper into an aspect of a Python library like L for instance, it&#39;s critical to know the basic concepts of Object Oriented Programming. This is because everything in Python is written as a Class. To get a good understanding of OOPs in Python, you can check out this great free resource here . Creating an L . Creating an instance &#39;a&#39; of class L from a list or any other normal iterable: . a = L([1, 2, 3]) a . (#3) [1,2,3] . We can use Python&#39;s isinstance method to check if a is an instance of L: . isinstance(a, L) . True . For Creating an &#39;L&#39; from an array or tensor we need to pass use_list=True since it doesn&#39;t iterate over them on construction. . By default we get something like this: . L(array([0.,1.1])) . (#1) [array([0. , 1.1])] . And when using use_list we get: . L(array([0.,1.1]), use_list=True) . (#2) [0.0,1.1] . # To see a realtime example when working with datasets in Fastai path = untar_data(URLs.PETS) Path.BASE_PATH = path files = get_image_files(path) . Here files is an L which can be also be checked by looking at its type as follows: . type(files) . fastcore.foundation.L . Let&#39;s take a look a better look at the class L using the help function: . #collapse-hide help(L) . . Help on class L in module fastcore.foundation: class L(CollBase) | L(self, items=None, *rest, use_list=False, match=None) | | Behaves like a list of `items` but can also index with list of indices or masks | | Method resolution order: | L | CollBase | builtins.object | | Methods defined here: | | __add__(a, b) | | __addi__(a, b) | | __contains__(self, b) | | __eq__(self, b) | Return self==value. | | __getitem__(self, idx) | Retrieve `idx` (can be list of indices, or mask, or int) items | | __init__(self, items=None, *rest, use_list=False, match=None) | Initialize self. See help(type(self)) for accurate signature. | | __invert__(self) | | __iter__(self) | | __mul__(a, b) | | __radd__(a, b) | | __repr__(self) | Return repr(self). | | __setitem__(self, idx, o) | Set `idx` (can be list of indices, or mask, or int) items to `o` (which is broadcast if not iterable) | | append(self, o) | Passthru to `list` method | | argwhere(self, f, negate=False, **kwargs) | Like `filter`, but return indices for matching items | | attrgot(self, k, default=None) | Create new `L` with attr `k` of all `items` | | cat(self: fastcore.foundation.L, dim=0) | Same as `torch.cat` | | clear(self) | Passthru to `list` method | | concat(self) | Concatenate all elements of list | | copy(self) | Same as `list.copy`, but returns an `L` | | count(self, o) | Passthru to `list` method | | cycle(self) | Same as `itertools.cycle` | | enumerate(self) | Same as `enumerate` | | filter(self, f, negate=False, **kwargs) | Create new `L` filtered by predicate `f`, passing `args` and `kwargs` to `f` | | index(self, value, start=0, stop=9223372036854775807) | Passthru to `list` method | | itemgot(self, *idxs) | Create new `L` with item `idx` of all `items` | | map(self, f, *args, **kwargs) | Create new `L` with `f` applied to all `items`, passing `args` and `kwargs` to `f` | | map_dict(self, f=&lt;function noop at 0xb1f55f488&gt;, *args, **kwargs) | Like `map`, but creates a dict from `items` to function results | | map_zip(self, f, *args, cycled=False, **kwargs) | Combine `zip` and `starmap` | | map_zipwith(self, f, *rest, cycled=False, **kwargs) | Combine `zipwith` and `starmap` | | pop(self, o=-1) | Passthru to `list` method | | product(self) | Product of the items | | reduce(self, f, initial=None) | Wrapper for `functools.reduce` | | remove(self, o) | Passthru to `list` method | | reverse(self) | Passthru to `list` method | | shuffle(self) | Same as `random.shuffle`, but not inplace | | sort(self, key=None, reverse=False) | Passthru to `list` method | | sorted(self, key=None, reverse=False) | New `L` sorted by `key`. If key is str then use `attrgetter`. If key is int then use `itemgetter` | | stack(self: fastcore.foundation.L, dim=0) | Same as `torch.stack` | | starmap(self, f, *args, **kwargs) | Like `map`, but use `itertools.starmap` | | sum(self) | Sum of the items | | tensored(self: fastcore.foundation.L) | `mapped(tensor)` | | unique(self) | Unique items, in stable order | | val2idx(self) | Dict from value to index | | zip(self, cycled=False) | Create new `L` with `zip(*items)` | | zipwith(self, *rest, cycled=False) | Create new `L` with `self` zip with each of `*rest` | | - | Class methods defined here: | | range(a, b=None, step=None) from fastcore.foundation.NewChkMeta | Same as `range`, but returns an `L`. Can pass a collection for `a`, to use `len(a)` | | split(s, sep=None, maxsplit=-1) from fastcore.foundation.NewChkMeta | Same as `str.split`, but returns an `L` | | - | Data and other attributes defined here: | | __hash__ = None | | __signature__ = &lt;Signature (self, items=None, *rest, use_list=False, m... | | - | Methods inherited from CollBase: | | __delitem__(self, i) | | __len__(self) | | - | Data descriptors inherited from CollBase: | | __dict__ | dictionary for instance variables (if defined) | | __weakref__ | list of weak references to the object (if defined) . We can see that L inherits from class CollBase. . CollBase . We can see that L&#39;s Method resolution order: . L | CollBase | builtins.object | . Fastai source code defines CollBase as a &quot;Base class for composing a list of items&quot; . We can check is issubclass method in Python to check if a particular class is a subclass of another: . issubclass(L, CollBase) . True . Let&#39;s look at the source code for L again using ?? in Jupyter: . L?? . We can see in the initialization a line: . super().__init__(items) . This indicates that if any items is passed to L, for instance a list, the initialization is handled by CollBase. . Now if you look at the source code of CollBase we can see the same as well as some other methods to deal with the items. . CollBase?? . From the source code we can gather that CollBase has a bunch of methods to deal with the items added to it such as it&#39;s creation, the manipulation of the items. . The methods available in L . Let&#39;s now look at all the methods available in L using the dir method in Python: . #collapse-show dir(L) . . [&#39;__add__&#39;, &#39;__addi__&#39;, &#39;__class__&#39;, &#39;__contains__&#39;, &#39;__delattr__&#39;, &#39;__delitem__&#39;, &#39;__dict__&#39;, &#39;__dir__&#39;, &#39;__doc__&#39;, &#39;__eq__&#39;, &#39;__format__&#39;, &#39;__ge__&#39;, &#39;__getattribute__&#39;, &#39;__getitem__&#39;, &#39;__gt__&#39;, &#39;__hash__&#39;, &#39;__init__&#39;, &#39;__init_subclass__&#39;, &#39;__invert__&#39;, &#39;__iter__&#39;, &#39;__le__&#39;, &#39;__len__&#39;, &#39;__lt__&#39;, &#39;__module__&#39;, &#39;__mul__&#39;, &#39;__ne__&#39;, &#39;__new__&#39;, &#39;__radd__&#39;, &#39;__reduce__&#39;, &#39;__reduce_ex__&#39;, &#39;__repr__&#39;, &#39;__setattr__&#39;, &#39;__setitem__&#39;, &#39;__signature__&#39;, &#39;__sizeof__&#39;, &#39;__str__&#39;, &#39;__subclasshook__&#39;, &#39;__weakref__&#39;, &#39;_default&#39;, &#39;_get&#39;, &#39;_new&#39;, &#39;_xtra&#39;, &#39;append&#39;, &#39;argwhere&#39;, &#39;attrgot&#39;, &#39;cat&#39;, &#39;clear&#39;, &#39;concat&#39;, &#39;copy&#39;, &#39;count&#39;, &#39;cycle&#39;, &#39;enumerate&#39;, &#39;filter&#39;, &#39;index&#39;, &#39;itemgot&#39;, &#39;map&#39;, &#39;map_dict&#39;, &#39;map_zip&#39;, &#39;map_zipwith&#39;, &#39;pop&#39;, &#39;product&#39;, &#39;range&#39;, &#39;reduce&#39;, &#39;remove&#39;, &#39;reverse&#39;, &#39;shuffle&#39;, &#39;sort&#39;, &#39;sorted&#39;, &#39;split&#39;, &#39;stack&#39;, &#39;starmap&#39;, &#39;sum&#39;, &#39;tensored&#39;, &#39;unique&#39;, &#39;val2idx&#39;, &#39;zip&#39;, &#39;zipwith&#39;] . . We can see that the methods associated with can be clearly distinguished into two parts: . Methods starting and ending with __: These are refered to a dunder or magic methods of a class in Python . | Methods starting with _: These are methods defined specifically in the Fastai library. . | Normal methods: These are the normal methods defined to a class in Python. . | . 1. Special/ Dunder/ Magic Methods . These special methods are used to emulate built-in methods in python that contributes with to ease of usability. . Since everything in Python is basically a class we can use these in-built methods for our own class by implementing something known as &#39;operator overloading&#39; to modify its behaviour as we intend to. . 1.1 __getitem__ . We can check how each method works by using the &#39;??&#39; in jupyter notebooks after the method name . a.__getitem__?? . Or we can use the help method: . help(a.__getitem__) . Help on method __getitem__ in module fastcore.foundation: __getitem__(idx) method of fastcore.foundation.L instance Retrieve `idx` (can be list of indices, or mask, or int) items . We can access the index of an L as follows: . a.__getitem__(0) . 1 . Or in the more appealing way by indexing as follows: . a[0] . 1 . In practical terms, in case we want to see one image file path when building a model we can do it as follows: . files[0] . Path(&#39;images/Egyptian_Mau_167.jpg&#39;) . Note:Internally in Python, when we index as iterable like L as hsown aboev, it internally calls the __getitem__ method. . 1.2 __setitem__ . help(a.__setitem__) . Help on method __setitem__ in module fastcore.foundation: __setitem__(idx, o) method of fastcore.foundation.L instance Set `idx` (can be list of indices, or mask, or int) items to `o` (which is broadcast if not iterable) . __setitem__ also takes an index and the value we want to add and we can do it as follows: . a[1] = 0 a . (#3) [1,0,3] . Internally, the above method is doing the same as below: . a.__setitem__(1, 4) a . (#3) [1,4,3] . 1.3 __contains__ . #collapse-hide help(a.__contains__) . . Help on method __contains__ in module fastcore.foundation: __contains__(b) method of fastcore.foundation.L instance . a = L([1, 2, 3]); a . (#3) [1,2,3] . We can use __contains__ to check if an element is in L as follows: . 1 in a . True . Internally in Python, this is what is happening: . a.__contains__(1) . True . 1.4 __delitem__ . help(a.__delitem__) . Help on method __delitem__ in module fastcore.foundation: __delitem__(i) method of fastcore.foundation.L instance . a = L([1, 2, 3]) . We can delete items in L as follows: . a.__delitem__(0) a . (#2) [2,3] . Or we can do it as follows: . del(a[0]) a . (#1) [3] . files[0] . Path(&#39;images/Egyptian_Mau_167.jpg&#39;) . 1.5 __mul__ . a = L([1, 2, 3]) . a.__mul__?? . a*3 . (#9) [1,2,3,1,2,3,1,2,3] . The above code is same as doing: a.__mul__(3) . Internally in Python this is what is actually being called. . 2. Fastai Specific Methods . The available special methods is Fastai&#39;s `L` class are: [&#39;_default&#39;, &#39;_get&#39;, &#39;_new&#39;, &#39;_xtra&#39;] . Out of these methods the only interesting method is _new so lets look at that: . 2.1 _new . a = L([1, 2, 3]); a . (#3) [1,2,3] . help(a._new) . Help on method _new in module fastcore.foundation: _new(items, *args, **kwargs) method of fastcore.foundation.L instance . a._new?? . The _new creates a new instance of L which requires some items to be passed to it. . a . (#3) [1,2,3] . Soft copy . a = L([1, 2, 3]) . b = a._new(a.items) b . (#3) [1,2,3] . id(a), id(b) . (112557760920, 112557761760) . a.append(4) a . (#4) [1,2,3,4] . b . (#4) [1,2,3,4] . Note: The __mul__ function uses _new, it returns:a._new(a.items*b) . 3. Normal Methods . 2.1 append . Very similar to a list in python, even &#39;L&#39; has an append method . a.append?? . a = L([1, 2, 3]) a.append(4) a . (#4) [1,2,3,4] . 2.2 arttrgot . This method can be used to get specific attributes from all items in L . #collapse-hide help(L.attrgot) . . Help on function attrgot in module fastcore.foundation: attrgot(self, k, default=None) Create new `L` with attr `k` of all `items` . L.attrgot?? . attrgot is a simple function that just maps getattr and the attribute you pass to an L. . attrgot is a pretty useful function and here&#39;s a practical example of where you can use it to get the name or stem attribute from paths. . ten_file_names = files[:10].attrgot(&#39;name&#39;) ten_file_names . (#10) [&#39;Egyptian_Mau_167&#39;,&#39;pug_52&#39;,&#39;basset_hound_112&#39;,&#39;Siamese_193&#39;,&#39;shiba_inu_122&#39;,&#39;Siamese_53&#39;,&#39;Birman_167&#39;,&#39;leonberger_6&#39;,&#39;Siamese_47&#39;,&#39;shiba_inu_136&#39;] . The stem attribute calculates the name without the file extensions as well . ten_file_stems = files[:10].attrgot(&#39;stem&#39;) ten_file_stems . (#10) [&#39;Egyptian_Mau_167&#39;,&#39;pug_52&#39;,&#39;basset_hound_112&#39;,&#39;Siamese_193&#39;,&#39;shiba_inu_122&#39;,&#39;Siamese_53&#39;,&#39;Birman_167&#39;,&#39;leonberger_6&#39;,&#39;Siamese_47&#39;,&#39;shiba_inu_136&#39;] . 2.3 enumerate . #collapse-hide help(L.enumerate) . . Help on function enumerate in module fastcore.foundation: enumerate(self) Same as `enumerate` . ten_file_names.enumerate() . (#10) [(0, &#39;Egyptian_Mau_167&#39;),(1, &#39;pug_52&#39;),(2, &#39;basset_hound_112&#39;),(3, &#39;Siamese_193&#39;),(4, &#39;shiba_inu_122&#39;),(5, &#39;Siamese_53&#39;),(6, &#39;Birman_167&#39;),(7, &#39;leonberger_6&#39;),(8, &#39;Siamese_47&#39;),(9, &#39;shiba_inu_136&#39;)] . enumerate returns an L where each element is tuple with the index(0th indexing) and the item itself. . We can use it something like this in a loop to build something from it if in case we need the index as well as the item for some manipulations . for i, file in enumerate(ten_file_names): print(i, file) . 0 Egyptian_Mau_167.jpg 1 pug_52.jpg 2 basset_hound_112.jpg 3 Siamese_193.jpg 4 shiba_inu_122.jpg 5 Siamese_53.jpg 6 Birman_167.jpg 7 leonberger_6.jpg 8 Siamese_47.jpg 9 shiba_inu_136.jpg . 2.4 filter . #collapse-hide help(L.filter) . . Help on function filter in module fastcore.foundation: filter(self, f, negate=False, **kwargs) Create new `L` filtered by predicate `f`, passing `args` and `kwargs` to `f` . filter is used to return items in an L that pass a function. . For instance we can use it to get all the items in files which start with upper case. Based on the PETS dataset, all such names that start with uppercase indicates that its a cat. . ten_file_names.filter(lambda x: x[0].isupper()) . (#5) [&#39;Egyptian_Mau_167.jpg&#39;,&#39;Siamese_193.jpg&#39;,&#39;Siamese_53.jpg&#39;,&#39;Birman_167.jpg&#39;,&#39;Siamese_47.jpg&#39;] . with negate=True we can get the vice-versa, i.e. all the dog image files: . ten_file_names.filter(lambda x: x[0].isupper(), negate=True) . (#5) [&#39;pug_52.jpg&#39;,&#39;basset_hound_112.jpg&#39;,&#39;shiba_inu_122.jpg&#39;,&#39;leonberger_6.jpg&#39;,&#39;shiba_inu_136.jpg&#39;] . 2.5 map . #collapse-hide help(L.map) . . Help on function map in module fastcore.foundation: map(self, f, *args, **kwargs) Create new `L` with `f` applied to all `items`, passing `args` and `kwargs` to `f` . map is used to map a function over all elements of L . L.range(4).map(lambda x: x**2) . (#4) [0,1,4,9] . 2. 6 map_dict . #collapse-hide help(L.map_dict) . . Help on function map_dict in module fastcore.foundation: map_dict(self, f=&lt;function noop at 0xb220cc6a8&gt;, *args, **kwargs) Like `map`, but creates a dict from `items` to function results . map_dict applies a function over &#39;L&#39; to return a dict where the dictionary&#39;s items are the original elements and its values are the modified values after applying the function. . L.range(1, 4).map_dict(lambda x: x**2) . {1: 1, 2: 4, 3: 9} . 2.7 zip . #collapse-hide help(L.zip) . . Help on function zip in module fastcore.foundation: zip(self, cycled=False) Create new `L` with `zip(*items)` . a = L([1, 2, 3], &#39;abc&#39;) a . (#2) [[1, 2, 3],&#39;abc&#39;] . a.zip() . (#3) [(1, &#39;a&#39;),(2, &#39;b&#39;),(3, &#39;c&#39;)] . 2.8 split . L.split(&#39;a/b/c&#39;, sep=&#39;/&#39;) . (#3) [&#39;a&#39;,&#39;b&#39;,&#39;c&#39;] . 2.9 concat . help(L.concat) . Help on function concat in module fastcore.foundation: concat(self) Concatenate all elements of list . L.concat?? . a = L([1, 2, 3, [&#39;abc&#39;]]) a . (#3) [1,2,[&#39;abc&#39;]] . a.append([&#39;def&#39;]) a . (#4) [1,2,[&#39;abc&#39;],[&#39;def&#39;]] . a.concat() . (#4) [1,2,&#39;abc&#39;,&#39;def&#39;] . b = L([[[1, 2], 3], [4, 5]]) b.concat().concat() . (#5) [1,2,3,4,5] . . Conclusion . The L data structure created in Fastai V2 is extremely useful and has some really power functionality. I am still digging into the depths of Fastai V2 and as I go along with it i&#39;ll try to update this in terms of the practical usability of the methods in its class for building state-of-the-art models using the library. . . Happy learning! Stay home and stay safe :) . .",
            "url": "https://harish3110.github.io/through-tinted-lenses/2020/04/03/A-look-at-Fastai's-L-Data-Structure.html",
            "relUrl": "/2020/04/03/A-look-at-Fastai's-L-Data-Structure.html",
            "date": " • Apr 3, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "Building an image classifier using Fastai V2",
            "content": ". I would like to start these series of posts with an introduction to the fastai v2 library in the application of vision, which is arguably the most common application in the field, and definitely, the most worked on. . . Importing the library and necessary modules . from data.utils import * from fastai2.vision.all import * %matplotlib inline . Note: The first line imports some helper functions from utils.py as used in the fastbook repo which provides great visualization options. . . About the dataset . Let&#39;s start with the Flowers dataset, which is a common dataset for image classification tasks. The dataset is a collection of images of 102 different types of flowers, which is nicely curated. The images are of fairly reasonable size shot in different angles and lighting conditions. . Here&#39;s a list of the 102 different categories of flowers in this dataset for your reference. . . Getting and exploring the dataset . Now that we have our arsenal set up and have an understanding of the data we are working. Let&#39;s download it and explore it. . About 90% of the work done by data scientist revolves around clearly gathering data. For simplicity, let&#39;s begin with commonly available datasets. . Fastai library makes it extremely easy to get common well-know datasets and is stored in Amazon S3 buckets for fast retrieval and use. They&#39;re all stored in the URLs global constant. . flowers_link = URLs.FLOWERS flowers_link . &#39;https://s3.amazonaws.com/fast-ai-imageclas/oxford-102-flowers.tgz&#39; . path = untar_data(flowers_link) path.ls() . (#4) [Path(&#39;/home/jupyter/.fastai/data/oxford-102-flowers/valid.txt&#39;),Path(&#39;/home/jupyter/.fastai/data/oxford-102-flowers/test.txt&#39;),Path(&#39;/home/jupyter/.fastai/data/oxford-102-flowers/jpg&#39;),Path(&#39;/home/jupyter/.fastai/data/oxford-102-flowers/train.txt&#39;)] . The above response may appear like a datastructure similar to a list in Python, but it&#39;s a built-in fastai data structure called &#39;L.&#39; You can think of it as a data structure, which is an amalgamation of lists and dicts in Python. . The above output begins with a tuple &#39;#4&#39;, which indicates that the path has 4 sub-directories in it and then displays those directories as an array. . To see the directories better, let&#39;s just see the base path of the sub directories instead of the entire path. . Path.BASE_PATH = path path.ls() . (#4) [Path(&#39;valid.txt&#39;),Path(&#39;test.txt&#39;),Path(&#39;jpg&#39;),Path(&#39;train.txt&#39;)] . # !pip install tree !tree -d {path} . /home/jupyter/.fastai/data/oxford-102-flowers └── jpg 1 directory . Now we can clearly see that the directory has one folder and three .txt files: . jpg: A folder containing all the images of the dataset | txt files: 3 text files indicating train, test, and validation. | . Let&#39;s look into the &#39;jpg&#39; folder: . Fastai provides an in-built function, get_image_files to get all image files in a folder as an &#39;L&#39;. . files = get_image_files(path/&#39;jpg&#39;) files . (#8189) [Path(&#39;jpg/image_03449.jpg&#39;),Path(&#39;jpg/image_05274.jpg&#39;),Path(&#39;jpg/image_03731.jpg&#39;),Path(&#39;jpg/image_07311.jpg&#39;),Path(&#39;jpg/image_05189.jpg&#39;),Path(&#39;jpg/image_06695.jpg&#39;),Path(&#39;jpg/image_06706.jpg&#39;),Path(&#39;jpg/image_04746.jpg&#39;),Path(&#39;jpg/image_04017.jpg&#39;),Path(&#39;jpg/image_06632.jpg&#39;)...] . We can see that there are 8189 images in the dataset available to us. Let&#39;s look at one of the images. . img = PILImage.create(files[0]) img.show() . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7fcf6f598650&gt; . Now let&#39;s look at the .txt files using pandas. Pandas is the go-to method for dealing with a tabular structure in python and is an essential skill for all data scientists using python. . Pandas can read many formats of data such as CSV, Excel, as well as text files very quickly by creating a pandas dataframe for manipulating it accordingly. . train = pd.read_csv(path/&#39;train.txt&#39;, header=None, sep=&#39; &#39;) train.head() #head displays the first 5 rows of the dataframe . 0 1 . 0 jpg/image_03860.jpg | 16 | . 1 jpg/image_06092.jpg | 13 | . 2 jpg/image_02400.jpg | 42 | . 3 jpg/image_02852.jpg | 55 | . 4 jpg/image_07710.jpg | 96 | . We can see that the file contains the image file name and its corresponding labels. So let&#39;s label the columns of the pandas dataframe accordingly. . cols = [&#39;name&#39;, &#39;label&#39;] train.columns = cols train.head() . name label . 0 jpg/image_03860.jpg | 16 | . 1 jpg/image_06092.jpg | 13 | . 2 jpg/image_02400.jpg | 42 | . 3 jpg/image_02852.jpg | 55 | . 4 jpg/image_07710.jpg | 96 | . Now that we have an organized structuring for our training files. Let&#39;s do the same to create a validation and test dataframe. . # validation df valid = pd.read_csv(path/&#39;valid.txt&#39;, sep=&quot; &quot;, names= cols ) # test df test = pd.read_csv(path/&#39;test.txt&#39;, sep=&quot; &quot;, names= cols ) . valid.head() . name label . 0 jpg/image_04467.jpg | 89 | . 1 jpg/image_07129.jpg | 44 | . 2 jpg/image_05166.jpg | 4 | . 3 jpg/image_07002.jpg | 34 | . 4 jpg/image_02007.jpg | 79 | . test.head() . name label . 0 jpg/image_06977.jpg | 34 | . 1 jpg/image_00800.jpg | 80 | . 2 jpg/image_05038.jpg | 58 | . 3 jpg/image_06759.jpg | 0 | . 4 jpg/image_01133.jpg | 45 | . Let&#39;s see the count of images in each one of the train, validation and test datasets. . print(f&quot;The number of images in training set are:{len(train)}&quot;) print(f&quot;The number of images in validation set are:{len(valid)}&quot;) print(f&quot;The number of images in test set are:{len(valid)}&quot;) . The number of images in training set are:1020 The number of images in validation set are:1020 The number of images in test set are:1020 . We can see that we have a total of around 8000 labelled images to build our flower classifier of 102 different clases. Since the data we have ain&#39;t that much let&#39;s utilize all the data available to build our model. To do so let&#39;s first merge the 3 dataframes into one. . df = pd.concat([train, valid, test], axis=0) df.head() . name label . 0 jpg/image_03860.jpg | 16 | . 1 jpg/image_06092.jpg | 13 | . 2 jpg/image_02400.jpg | 42 | . 3 jpg/image_02852.jpg | 55 | . 4 jpg/image_07710.jpg | 96 | . The main dataframe consists of 8189 labeled images. . Let&#39;s now save this dataframe as a CSV file for ease of access later on. . df.to_csv(&#39;data/df.csv&#39;) . By looking at the above dataframe we can see that the images and numerically labelled by the creators of the datset, probably for easier mapping. This would make visualization pretty bad since we won&#39;t what flower we are seeing in the end. So let&#39;s get the mpping of the labels to the numerical assignemnt given here. . If you look at the main source of the dataset, the labels are provided in a .mat file and would be quite cumbersome to fetch. Luckily enough JosephKJ did the labelling and generously made it available for us here. I downloaded the .txt file and will read it using pandas. . labels = pd.read_csv(&#39;data/labels.txt&#39;, header=None, names = [&#39;labels&#39;]) labels[&#39;labels&#39;] = labels[&#39;labels&#39;].apply(lambda x: x.replace(&quot;&#39;&quot;, &quot;&quot;)) labels.head() . labels . 0 pink primrose | . 1 hard-leaved pocket orchid | . 2 canterbury bells | . 3 sweet pea | . 4 english marigold | . Now creating labels dictionary where key is the number and value is the respective name of the flower. . labels_dict = dict(zip(list(range(len(labels))), labels[&#39;labels&#39;])) . Let&#39;s use the all powerful pandas apply function again to map the numerical labels in df with the labels_dict . # Creating a new column &#39;class&#39; using the existing label of images df[&#39;class&#39;] = df[&#39;label&#39;].apply(lambda x: labels_dict[x]) df.head() . name label class . 0 jpg/image_03860.jpg | 16 | purple coneflower | . 1 jpg/image_06092.jpg | 13 | spear thistle | . 2 jpg/image_02400.jpg | 42 | sword lily | . 3 jpg/image_02852.jpg | 55 | bishop of llandaff | . 4 jpg/image_07710.jpg | 96 | mallow | . Now that we have arranged our data exactly as we want it, let&#39;s move ahead to model building using fastai library. . . The DataBlock API . We have our data structured well and exactly as we want. It&#39;s now time to feed it into the fastai library. This can be done using the DataBlocks API. . The DataBlocks API is the Fastai solution to simplifying the most time-consuming task in a data science pipeline, Data Preparation. It&#39;s easy to use, highly hackable and can be be used for a wide variety of data on applications such as vision, tabular, and text. . This DataBlock API is a much-needed addition to the fastai v2, which makes it super easy to load in data as needed for deep learning models. . def get_x(r): return path/r[&#39;name&#39;] def get_y(r): return r[&#39;class&#39;] dblock = DataBlock(blocks=(ImageBlock, CategoryBlock), splitter=RandomSplitter(seed=42), get_x= get_x, get_y= get_y, item_tfms = Resize(224)) dls = dblock.dataloaders(df) . Let&#39;s get a basic understanding of what&#39;s happening in the above code. Creating data which can be fed to a model requires two steps: . 1. Create a DataBlock: . A Datablock can be considered as a series of sequential functions all collated into one function. For people who have used sci-kit-learn, this can be considered similar to a pipeline. . The DataBlock API requires some methods to get the input data in the desired format for model building and training: . blocks: This is used to define the input and output of the model. In the above code, the type of input i.e. the independent variable, which are images and hence ImageBlock. The output, i.e., dependant variable, are categories of flowers and hence CategoryBlock. . | splitter: Splitters are used to divide our data into training and validation. This is of utmost importance because we don&#39;t want our model to train and memorize all the training images. We want a subset of images to validate how good our model is doing. In this case, we use a method that randomly splits data in train and validation. . | getters: Getters are used to get the independent and dependant variables in the right order. The two getters used are get_x and get_y. Here we defined get_x by grabbing the name of the image file from df and adding the path to it, and we set get_y by getting the class column from df. . | transforms: Transforms are used to perform data augmentation techniques on our input data either on the entire data(item_tfms) on the CPU or on the data passed as batches(batch_tfms) when passing it through the architecture on the GPU. In this case, we are just resizing all images to 224, which is mandatory as deep learning models need all our training images to be of the same size. . | . 2. Call the dataloaders method on your data: . A dataloaders is a method called on the DataBlock where we pass in our dataframe df to perform all the steps mentioned in the DataBlock, which finally returns the data in the required format for modeling. . . Visualizing the data . Now that we have made our data ready and in the format to be ingested by the fastai library, let&#39;s visualize our data. . We can use show_batch method from our dataloader created to visualize a batch of images and their labels. . dls.show_batch() . . Building the model . Let&#39;s build a deep learning model on our dataset using a Convolutional Neural Netwok(CNN) model. . Basic understanding of CNN&#39;s . Here&#39;s the general architecture of every CNN model . . Every CNN architecture consists of 4 parts: . Input layer: The input i.e. the image dataset with &#39;n&#39; classes which are correctly labeled on which our image classification model is built on. . | Feature extraction: This is the crux of the CNN model. It learns various features of the classes in your data and how to distinguish between them during the training process. For instance, during the training process, if images of dogs are passed in, the initial layers learn simple features such as lines, edges, circles. Still, as we move to later layers of the model, the model learns complex features like ears, nose, and eyes of the dog. In machine language, all these features are represented numerically, and we refer to all these learned features as parameters of the model. . | Classification: This part of the model is used to pool in the different features learned and associate it with the corresponding class. Continuing the example of our dog, it could mean that we pool in the features learned about the dog, such as its nose, eyes, tail, etc. and associate it with the output label, which is a dog. . | Output: This is the part that associates an input image to class as labeled in our training set. When a new image of a dog is sent through a trained model, the output class of the model will get activated and indicate that the input image is that of a dog. . | . The entire structure of the model built above is referred to as a model architecture in deep learning. . Now, we can build flower classifier from scratch, but since we only have 8000 odd images for 102 different classes. We can safely say that we don&#39;t have enough data to build a beautiful model from scratch. . Instead, let&#39;s use the biggest weapon in the deep learning arsenal available at our disposal, Transfer Learning. . . Transfer Learning . Transfer Learning is a method that uses the work done by other researchers who spend days on end to build appropriate architectures which train on large datasets for specific tasks. For instance, the ImageNet dataset, which consists of 1.3 million images of various sizes around 500 pixels across in 1000 categories, takes a few days to train. . The main idea is as follows, the ImageNet dataset has 1000 different everyday categories, and the parameters and features it learns for each one of the categories can be applied to make the building blocks of the flowers dataset we are working on. The initial feature extraction layers that learn simple features line lines, edges, circles, etc. can be applied to flowers as well, and we can fine-tune the final layers to distinguish between the different classes of flowers. . The final output layer(which is trained on 1000 categories) also needs to be removed and replaced with the 102 different classes of flowers. . . Defining the learner . In fastai, to build a model, we use the cnn_learner class. We need to pass in the following details to the cnn_learner to train the model: . Dataloaders object: The dls dataloader we created according to how fastai needs the input data. | Model Architecture: This is the architecture we would like to use. Since we are making use of transfer learning, we&#39;ll use a pretrained model, in this case, the famous resnet34 architecture. | Metrics: This is how you would like to keep track of your training progress. In this case, we&#39;ll use accuracy, which indicates how well our model classifies all the classes in our data overall. | . learn = cnn_learner(dls, resnet34, metrics=accuracy) . Let&#39;s visualize the model architecture used i.e the resnet34 architecture . learn.summary() . Sequential (Input shape: [&#39;64 x 3 x 224 x 224&#39;]) ================================================================ Layer (type) Output Shape Param # Trainable ================================================================ Conv2d 64 x 64 x 112 x 112 9,408 False ________________________________________________________________ BatchNorm2d 64 x 64 x 112 x 112 128 True ________________________________________________________________ ReLU 64 x 64 x 112 x 112 0 False ________________________________________________________________ MaxPool2d 64 x 64 x 56 x 56 0 False ________________________________________________________________ Conv2d 64 x 64 x 56 x 56 36,864 False ________________________________________________________________ BatchNorm2d 64 x 64 x 56 x 56 128 True ________________________________________________________________ ReLU 64 x 64 x 56 x 56 0 False ________________________________________________________________ Conv2d 64 x 64 x 56 x 56 36,864 False ________________________________________________________________ BatchNorm2d 64 x 64 x 56 x 56 128 True ________________________________________________________________ Conv2d 64 x 64 x 56 x 56 36,864 False ________________________________________________________________ BatchNorm2d 64 x 64 x 56 x 56 128 True ________________________________________________________________ ReLU 64 x 64 x 56 x 56 0 False ________________________________________________________________ Conv2d 64 x 64 x 56 x 56 36,864 False ________________________________________________________________ BatchNorm2d 64 x 64 x 56 x 56 128 True ________________________________________________________________ Conv2d 64 x 64 x 56 x 56 36,864 False ________________________________________________________________ BatchNorm2d 64 x 64 x 56 x 56 128 True ________________________________________________________________ ReLU 64 x 64 x 56 x 56 0 False ________________________________________________________________ Conv2d 64 x 64 x 56 x 56 36,864 False ________________________________________________________________ BatchNorm2d 64 x 64 x 56 x 56 128 True ________________________________________________________________ Conv2d 64 x 128 x 28 x 28 73,728 False ________________________________________________________________ BatchNorm2d 64 x 128 x 28 x 28 256 True ________________________________________________________________ ReLU 64 x 128 x 28 x 28 0 False ________________________________________________________________ Conv2d 64 x 128 x 28 x 28 147,456 False ________________________________________________________________ BatchNorm2d 64 x 128 x 28 x 28 256 True ________________________________________________________________ Conv2d 64 x 128 x 28 x 28 8,192 False ________________________________________________________________ BatchNorm2d 64 x 128 x 28 x 28 256 True ________________________________________________________________ Conv2d 64 x 128 x 28 x 28 147,456 False ________________________________________________________________ BatchNorm2d 64 x 128 x 28 x 28 256 True ________________________________________________________________ ReLU 64 x 128 x 28 x 28 0 False ________________________________________________________________ Conv2d 64 x 128 x 28 x 28 147,456 False ________________________________________________________________ BatchNorm2d 64 x 128 x 28 x 28 256 True ________________________________________________________________ Conv2d 64 x 128 x 28 x 28 147,456 False ________________________________________________________________ BatchNorm2d 64 x 128 x 28 x 28 256 True ________________________________________________________________ ReLU 64 x 128 x 28 x 28 0 False ________________________________________________________________ Conv2d 64 x 128 x 28 x 28 147,456 False ________________________________________________________________ BatchNorm2d 64 x 128 x 28 x 28 256 True ________________________________________________________________ Conv2d 64 x 128 x 28 x 28 147,456 False ________________________________________________________________ BatchNorm2d 64 x 128 x 28 x 28 256 True ________________________________________________________________ ReLU 64 x 128 x 28 x 28 0 False ________________________________________________________________ Conv2d 64 x 128 x 28 x 28 147,456 False ________________________________________________________________ BatchNorm2d 64 x 128 x 28 x 28 256 True ________________________________________________________________ Conv2d 64 x 256 x 14 x 14 294,912 False ________________________________________________________________ BatchNorm2d 64 x 256 x 14 x 14 512 True ________________________________________________________________ ReLU 64 x 256 x 14 x 14 0 False ________________________________________________________________ Conv2d 64 x 256 x 14 x 14 589,824 False ________________________________________________________________ BatchNorm2d 64 x 256 x 14 x 14 512 True ________________________________________________________________ Conv2d 64 x 256 x 14 x 14 32,768 False ________________________________________________________________ BatchNorm2d 64 x 256 x 14 x 14 512 True ________________________________________________________________ Conv2d 64 x 256 x 14 x 14 589,824 False ________________________________________________________________ BatchNorm2d 64 x 256 x 14 x 14 512 True ________________________________________________________________ ReLU 64 x 256 x 14 x 14 0 False ________________________________________________________________ Conv2d 64 x 256 x 14 x 14 589,824 False ________________________________________________________________ BatchNorm2d 64 x 256 x 14 x 14 512 True ________________________________________________________________ Conv2d 64 x 256 x 14 x 14 589,824 False ________________________________________________________________ BatchNorm2d 64 x 256 x 14 x 14 512 True ________________________________________________________________ ReLU 64 x 256 x 14 x 14 0 False ________________________________________________________________ Conv2d 64 x 256 x 14 x 14 589,824 False ________________________________________________________________ BatchNorm2d 64 x 256 x 14 x 14 512 True ________________________________________________________________ Conv2d 64 x 256 x 14 x 14 589,824 False ________________________________________________________________ BatchNorm2d 64 x 256 x 14 x 14 512 True ________________________________________________________________ ReLU 64 x 256 x 14 x 14 0 False ________________________________________________________________ Conv2d 64 x 256 x 14 x 14 589,824 False ________________________________________________________________ BatchNorm2d 64 x 256 x 14 x 14 512 True ________________________________________________________________ Conv2d 64 x 256 x 14 x 14 589,824 False ________________________________________________________________ BatchNorm2d 64 x 256 x 14 x 14 512 True ________________________________________________________________ ReLU 64 x 256 x 14 x 14 0 False ________________________________________________________________ Conv2d 64 x 256 x 14 x 14 589,824 False ________________________________________________________________ BatchNorm2d 64 x 256 x 14 x 14 512 True ________________________________________________________________ Conv2d 64 x 256 x 14 x 14 589,824 False ________________________________________________________________ BatchNorm2d 64 x 256 x 14 x 14 512 True ________________________________________________________________ ReLU 64 x 256 x 14 x 14 0 False ________________________________________________________________ Conv2d 64 x 256 x 14 x 14 589,824 False ________________________________________________________________ BatchNorm2d 64 x 256 x 14 x 14 512 True ________________________________________________________________ Conv2d 64 x 512 x 7 x 7 1,179,648 False ________________________________________________________________ BatchNorm2d 64 x 512 x 7 x 7 1,024 True ________________________________________________________________ ReLU 64 x 512 x 7 x 7 0 False ________________________________________________________________ Conv2d 64 x 512 x 7 x 7 2,359,296 False ________________________________________________________________ BatchNorm2d 64 x 512 x 7 x 7 1,024 True ________________________________________________________________ Conv2d 64 x 512 x 7 x 7 131,072 False ________________________________________________________________ BatchNorm2d 64 x 512 x 7 x 7 1,024 True ________________________________________________________________ Conv2d 64 x 512 x 7 x 7 2,359,296 False ________________________________________________________________ BatchNorm2d 64 x 512 x 7 x 7 1,024 True ________________________________________________________________ ReLU 64 x 512 x 7 x 7 0 False ________________________________________________________________ Conv2d 64 x 512 x 7 x 7 2,359,296 False ________________________________________________________________ BatchNorm2d 64 x 512 x 7 x 7 1,024 True ________________________________________________________________ Conv2d 64 x 512 x 7 x 7 2,359,296 False ________________________________________________________________ BatchNorm2d 64 x 512 x 7 x 7 1,024 True ________________________________________________________________ ReLU 64 x 512 x 7 x 7 0 False ________________________________________________________________ Conv2d 64 x 512 x 7 x 7 2,359,296 False ________________________________________________________________ BatchNorm2d 64 x 512 x 7 x 7 1,024 True ________________________________________________________________ AdaptiveAvgPool2d 64 x 512 x 1 x 1 0 False ________________________________________________________________ AdaptiveMaxPool2d 64 x 512 x 1 x 1 0 False ________________________________________________________________ Flatten 64 x 1024 0 False ________________________________________________________________ BatchNorm1d 64 x 1024 2,048 True ________________________________________________________________ Dropout 64 x 1024 0 False ________________________________________________________________ Linear 64 x 512 524,288 True ________________________________________________________________ ReLU 64 x 512 0 False ________________________________________________________________ BatchNorm1d 64 x 512 1,024 True ________________________________________________________________ Dropout 64 x 512 0 False ________________________________________________________________ Linear 64 x 102 52,224 True ________________________________________________________________ Total params: 21,864,256 Total trainable params: 596,608 Total non-trainable params: 21,267,648 Optimizer used: &lt;function Adam at 0x7fd0087225f0&gt; Loss function: FlattenedLoss of CrossEntropyLoss() Model frozen up to parameter group number 2 Callbacks: - TrainEvalCallback - Recorder - ProgressCallback . If you scroll down and read the summary, in the end, you can see that there are a total of around 21 million parameters, but only around 600k parameters are trainable. . This is because we have inherited a model trained extensively on the ImageNet dataset and are using the parameters learned by that model to train our model on 102 classes of flowers. . This means that the parameters learned early on in the model to distinguish various objects are kept as is, and the final layers are replaced to classify. . Fine-tuning pretrained model . Once we have created our learner based on a pretrained resnet34 model, let&#39;s train our learner on classifying the flowers. In fastai there&#39;s a learner method specifically to train a pretrained model called fine_tune quickly. . fine_tune by default trains the head, i.e. the additional part to the model we added for our classification of 102 flowers for one epoch and then unfreezes the all the weights and optimizes the entire model including the weights in the starting phase. . So in the first epoch, the model learns the 600k trainable parameters such that all 21 million parameters are trained roughly. In the consecutive 2 epochs, it optimizes the all these weights specifically for the task in hand, i.e. classifying 102 types of flowers. . learn.fine_tune(3) . epoch train_loss valid_loss accuracy time . 0 | 2.779661 | 0.685666 | 0.831399 | 00:24 | . epoch train_loss valid_loss accuracy time . 0 | 0.625886 | 0.277132 | 0.927306 | 00:32 | . 1 | 0.256375 | 0.147598 | 0.959071 | 00:32 | . 2 | 0.100605 | 0.139057 | 0.962737 | 00:32 | . We can see that by using the power of transfer learning, in 2 lines of code and 3 steps of training(epochs) which took about 30 seconds to train on small GPU we are able to build a flowers classifier which can classify between 102 types of flowers with greater than 96% accuracy! . This blows the original paper out of the water which came out in 2008 which used a non-DL approach to tackle this problem and received an accuracy of about 72.8% . . But this isn&#39;t really a fair comparison, so if we compare our basic model the current leaderboard for the flowers-102 dataset, we can see that the best accuracy on the entire dataset is about 99.7%. . So, this is a good starting point. This will act as our baseline model for future improvements and experimentation in order to come closer to the current benchmark. . So let&#39;s save this model so that we can build on from here form next time. . learn.save(&#39;flowers-baseline&#39;) . We&#39;ll slowly build upon this and make this model better while learning more about building state-of-the-art models in the upcoming posts. . . Learning resources . Corey Schafer&#39;s Python Tutorials | Corey Schafer&#39;s Pandas Tutorials | Fastai v2 Documentation . | Fastbook i.e Deep Learning for Coders with Fastai and Pytorch: AI Applications Without a PhD by Jeremy Howard and Sylvain Gugger . | Fastai DataBlock API walkthrough blog by Zach Mueller . | . Happy learning, stay at home and stay safe! :) . .",
            "url": "https://harish3110.github.io/through-tinted-lenses/fastai/image%20classification/2020/03/29/Building-an-image-classifier-using-Fastai-V2.html",
            "relUrl": "/fastai/image%20classification/2020/03/29/Building-an-image-classifier-using-Fastai-V2.html",
            "date": " • Mar 29, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "Relearning how to learn, deep.",
            "content": "“The illiterate of the 21st century will not be those who cannot read and write, but those who cannot learn, unlearn, and relearn. ” ― Alvin Toffler — . Fact: Deep learning is hard! . I have a background in Electronics Engineering and having studied in the sub-continent, the amount of exposure I have had with programming was virtually non-existent. Since graduating, I have slowly transitioned my way into the field of data science and machine learning. I had to start from scratch and building block after block all the necessary skills needed to call myself a capable data scientist, and successfully land myself a job in the field. . Whenever I meet anyone from a non-ML background and tell them I’m a data scientist, their response is almost always the same. They nod in appreciation and say something like, “That’s the future!” and that “I’m on the right path!”. They then begin asking questions about the areas like self-driving cars and other popular fields and finally land on to the million-dollar question. “Is it difficult to become a machine learning/deep learning engineer?”. To this, I always find myself lying by spouting out of phrases like “it’s easy” and “anyone can do it”! Whereas the fact of the matter is that despite there being some credibility to the statement, the learning curve ain’t that easy. . Being a self-learner, I learned how to code in Python, understood the fundamental concepts of data science and machine learning by following an array of popular MOOCs such as Coursera, Udacity, etc. as well as completed certifications from reputed colleges in India. It has been an incredible journey of learning, but it has definitely not been a cakewalk! There is always a huge learning curve, and even after you complete a course or certification, there’s still that void of not having built anything meaningful. Every one of the courses makes a point of conveying the theory and underlying maths well but almost always fail at delivering to students the necessary tools to go ahead and build something practical. There’s always the next step(s) that needs to be taken to actaully implement the knowledge learned in the course. Being able to understand the theory and math from gorund up was satifying to begin with but as you dig deeper and deeper, without being able to rapidly protype and experiment with the concepts takes a toll on the learning process! . . Enter Fastai . I first heard about Fastai and Jeremy Howard from my friends around version 1 of the course. I pushed it aside as one of the many courses suggested by people in the field due to their inherent allegiance to it having taken it. But over time, on Twitter, LinkedIn, and other sources, it had reached a point that I couldn’t not take a look at the course. So I finally succumbed to the pressure and started last year’s course. . . In less than two weeks, I binged watch through the entire part 1! The course was nothing like I had taken before. All the concepts explained intuitively and efficiently, and more importantly, everything taught was visualized through code and by building state-of-the-art models. I fell in love with the teaching methodology and with the community it had granered. I couldn’t but feel envious of the new students taking up the course to learn deep learning as I was comparing it to myself starting out in ML a year ago and how a course like this would have been extremely helpful to my past self. . Despite my best efforts, I didn’t feel like I put in the necessary commitment needed to make best use of the course due to other obligations. All this while I knew in the back of my head that i had to follow through on the course soon. So when I got the chance to take part in this year’s course(fastai v4), I didn’t think twice. I definitely wanted to take part in the course in person, but I’m equally glad to be taking part in the course virtually considering all that’s going around in the world at the moment! . . Fact: Deep learning is hard . Fact: Deep learning is easy if done right! . “There are Two Core Abilities for Thriving in the New Economy : . The ability to quickly master hard things. | The ability to produce at an elite level, in terms of both quality and speed.” ― Cal Newport | The main idea of the course and the library is to democratize this powerful tool of ‘Deep Learning’, such that it can be easily harnessed by people across all domains such that one apply the principles easily in their domain. . The course challenges the usual way of learning by following a top-down approach to understanding deep learning. In comparison to every other DL course under the sun, this course makes the field easy to approach, and most importantly, it helps implement the models very quickly. Students taking the class learn to apply all the theoretical concepts learned immediately with concrete examples rather than learn mathematical proofs. In a rapidly evolving field such as this, being able to learn and rapidly prototype simultaneously is invaluable! . Everything taught in this year’s course is again application-driven and closely follows the book written by the founders of fastai, Jeremy, and Sylvain. The only prerequisites needed to start with the course are high school math and intermediate coding skills in Python, which, to be honest, can be picked up along the way(I’ll be sure to put up references for all in the end). This doesn’t mean that the course is geared only for beginners. On the contrary, even veterans in the field will have a lot to discover and learn in the course. The course gradually wades through the ingenious implementations, tricks, and insights gained through experimentation by the fastai team, which has led them to achieve state-of-the-art benchmark models by beating top companies with considerably limited compute resources as compared to big guns in the field. . The lectures taught by Jeremy, the book as a manual to wade through the ‘frightening’ depths of deep learning, a fantastic community of like-minded and extremely helpful peers, is a complete package and the perfect recipe to learn. I couldn’t be more glad to be taking part in such an enriching learning experience, especially during these trying times, and despite it being virtual, I don’t believe it has lost a beat. . “What I hope is that lots of people will realize that state-of-the-art results of deep learning are something they can achieve even if they’re not a Stanford University deep learning PhD.” — Jeremy Howard . . My blog post series . There’s definitely a self-centered motivation to write these blog posts. Following the advice by Rachel Thomas(co-founder of fast.ai) in her blog post, she encourages anyone on a learning path to put out blog posts in order to maximize your learning. . But aside from the learning advantages, I would like to do my best in helping guide people entering this field on how best to navigate the myriad resources in the field and hopefully impart some of the knowledge learned along my journey until now. . Being quarantined, I find this time to be the best opportunity to start my blog by delving into depths of this fantastic deep-learning library! . The course is currently private but will be made public and free for all like all courses by fast.ai. Until then, and hopefully, even then, I hope I can help wade students through the mazes of Deep Learning, Fast.ai style! So let’s get into it! . In my upcoming blog post, i’ll provide an introduction to the fastai v2 library and build an image classifier on a well-known dataset. . “Education is the kindling of a flame, not the filling of a vessel.” ― Socrates . . Happy learning, stay at home and stay safe! :) .",
            "url": "https://harish3110.github.io/through-tinted-lenses/fastai/deep%20learning/2020/03/28/Relearning-how-to-learn-deep.html",
            "relUrl": "/fastai/deep%20learning/2020/03/28/Relearning-how-to-learn-deep.html",
            "date": " • Mar 28, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": ". Hi there, Harish here! . I am a data science and ML enthusiast trying to do my bit in the field. Apart from this I am a technology evangelist, a bibliophile, and a deranged Liverpool fan! :) . If you would like to provide some feedbac/suggestions on the content I post you can reach me out on my twitter handle. .",
          "url": "https://harish3110.github.io/through-tinted-lenses/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

}