<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Introducing Prometheus, my very own deep learning arsenal. | Through Tinted Lenses</title>
<meta name="generator" content="Jekyll v4.0.0" />
<meta property="og:title" content="Introducing Prometheus, my very own deep learning arsenal." />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Introducing Prometheus" />
<meta property="og:description" content="Introducing Prometheus" />
<link rel="canonical" href="https://harish3110.github.io/through-tinted-lenses/hardware/setup/2020/06/19/Introducing-Prometheus,-my-very-own-deep-learning-arsenal.html" />
<meta property="og:url" content="https://harish3110.github.io/through-tinted-lenses/hardware/setup/2020/06/19/Introducing-Prometheus,-my-very-own-deep-learning-arsenal.html" />
<meta property="og:site_name" content="Through Tinted Lenses" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-06-19T00:00:00-05:00" />
<script type="application/ld+json">
{"description":"Introducing Prometheus","headline":"Introducing Prometheus, my very own deep learning arsenal.","dateModified":"2020-06-19T00:00:00-05:00","datePublished":"2020-06-19T00:00:00-05:00","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://harish3110.github.io/through-tinted-lenses/hardware/setup/2020/06/19/Introducing-Prometheus,-my-very-own-deep-learning-arsenal.html"},"url":"https://harish3110.github.io/through-tinted-lenses/hardware/setup/2020/06/19/Introducing-Prometheus,-my-very-own-deep-learning-arsenal.html","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/through-tinted-lenses/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://harish3110.github.io/through-tinted-lenses/feed.xml" title="Through Tinted Lenses" /><link rel="shortcut icon" type="image/x-icon" href="/through-tinted-lenses/images/favicon.ico"><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Introducing Prometheus, my very own deep learning arsenal. | Through Tinted Lenses</title>
<meta name="generator" content="Jekyll v4.0.0" />
<meta property="og:title" content="Introducing Prometheus, my very own deep learning arsenal." />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Introducing Prometheus" />
<meta property="og:description" content="Introducing Prometheus" />
<link rel="canonical" href="https://harish3110.github.io/through-tinted-lenses/hardware/setup/2020/06/19/Introducing-Prometheus,-my-very-own-deep-learning-arsenal.html" />
<meta property="og:url" content="https://harish3110.github.io/through-tinted-lenses/hardware/setup/2020/06/19/Introducing-Prometheus,-my-very-own-deep-learning-arsenal.html" />
<meta property="og:site_name" content="Through Tinted Lenses" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-06-19T00:00:00-05:00" />
<script type="application/ld+json">
{"description":"Introducing Prometheus","headline":"Introducing Prometheus, my very own deep learning arsenal.","dateModified":"2020-06-19T00:00:00-05:00","datePublished":"2020-06-19T00:00:00-05:00","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://harish3110.github.io/through-tinted-lenses/hardware/setup/2020/06/19/Introducing-Prometheus,-my-very-own-deep-learning-arsenal.html"},"url":"https://harish3110.github.io/through-tinted-lenses/hardware/setup/2020/06/19/Introducing-Prometheus,-my-very-own-deep-learning-arsenal.html","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

<link href="https://unpkg.com/@primer/css/dist/primer.css" rel="stylesheet" />
<link rel="stylesheet" href="//use.fontawesome.com/releases/v5.0.7/css/all.css"><link type="application/atom+xml" rel="alternate" href="https://harish3110.github.io/through-tinted-lenses/feed.xml" title="Through Tinted Lenses" />

<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head><body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/through-tinted-lenses/">Through Tinted Lenses</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/through-tinted-lenses/about/">About Me</a><a class="page-link" href="/through-tinted-lenses/search/">Search</a><a class="page-link" href="/through-tinted-lenses/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Introducing Prometheus, my very own deep learning arsenal.</h1><p class="post-meta post-meta-title"><time class="dt-published" datetime="2020-06-19T00:00:00-05:00" itemprop="datePublished">
        Jun 19, 2020
      </time>
       • <span class="read-time" title="Estimated read time">
    
    
      7 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/through-tinted-lenses/categories/#hardware">hardware</a>
        &nbsp;
      
        <a class="category-tags-link" href="/through-tinted-lenses/categories/#setup">setup</a>
        
      
      </p>
    

    </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul class="section-nav">
<li class="toc-entry toc-h2"><a href="#introducing-prometheus">Introducing Prometheus</a></li>
<li class="toc-entry toc-h2"><a href="#why-own-a-deep-learning-workstation">Why own a Deep Learning workstation?</a></li>
<li class="toc-entry toc-h2"><a href="#should-you-build-your-own-workstation">Should you build your own workstation?</a></li>
<li class="toc-entry toc-h2"><a href="#components">Components</a>
<ul>
<li class="toc-entry toc-h3"><a href="#gpu">GPU</a></li>
<li class="toc-entry toc-h3"><a href="#cpu-and-motherboard">CPU and Motherboard</a></li>
<li class="toc-entry toc-h3"><a href="#ram">RAM</a></li>
<li class="toc-entry toc-h3"><a href="#cpu-cooler">CPU Cooler</a></li>
<li class="toc-entry toc-h3"><a href="#storage">Storage</a></li>
<li class="toc-entry toc-h3"><a href="#cabinet">Cabinet</a></li>
</ul>
</li>
</ul><h2 id="introducing-prometheus">
<a class="anchor" href="#introducing-prometheus" aria-hidden="true"><span class="octicon octicon-link"></span></a>Introducing Prometheus</h2>

<p><img src="https://drive.google.com/file/d/1d_x8ZjbLCPMiIDDLgiYgQ3ocgGY5LQY9/view?usp=sharing" alt="prometheus"></p>

<blockquote>
  <p>“In Greek mythology, Prometheus, meaning “forethought”) is a Titan, culture hero, and trickster figure who is credited with the creation of humanity from clay, and who defies the gods by stealing fire and giving it to humanity as civilization. Prometheus is known for his intelligence and as a champion of humankind and also seen as the author of the human arts and sciences generally.”</p>
</blockquote>

<h2 id="why-own-a-deep-learning-workstation">
<a class="anchor" href="#why-own-a-deep-learning-workstation" aria-hidden="true"><span class="octicon octicon-link"></span></a>Why own a Deep Learning workstation?</h2>

<p>Today, there are a myriad of cloud GPU instances one can use to dabble in the field of deep learning. Over the past year or so, I have used almost all the possible options available which has helped me grasp the concepts of the field as it has made it easy fro anyone to prototype the knowledge acquired in the field at an affordable cost. Most of these services also offer free tier options and provide <strong>almost</strong> immediate access to a GPU instance.</p>

<p>My overall favourite has been Google’s GCP which also provides a 300$ credit to all their users as well as the newly launched Colab Pro which in my opinion is the best value for money option for most DL enthusiasts as it gives you access to multiple GPU instances for a nomianl monthly fee. GCP’s main advantage is full command line access to your linux based server whereas Colab’s interface is quite intutive as well. Until recently, I had opted for the Colab Pro for most of my prototyping and finally renting a GCP instance to train large models on a hourly basis as required.</p>

<p>This being said, there are still dowsides to this setup which becomes way too evident as you start spending longer time using a setup mentioned above which I’m sure anyone in the field long enough can easily vouch for. Despite the fact that gaining access to a GPU instance has become way too easy, here the major downsides which has bugged me long enough in order to shell out and invest in building my own DL rig:</p>

<ul>
  <li>The setup process of getting your instance started with the correct requirements can be quite tedious and takes some time to get a hang of things in each cloud platform available.</li>
  <li>Pre-emptible instances, which are the free-tier option provided by cloud services can get really annoying as you can be kicked off the instance abruptly in the middle of your training process.</li>
  <li>On the other hand, the constant worry to ensure shutting down your device to avoid racking up the bill is definitely real.</li>
</ul>

<p>In short, having your workstation at hand gives you the much needed freedom to prototype models at the flick of your fingers and gets rid of all the friction involved in using the cloud options available. This is an extension to James Clear’s advice ‘make it easy’ which is basically to eliminate the friction involved in performing long-term rewarding habits.</p>

<blockquote>
  <p>“Human behaviour follows the Law of Least Effort. Reduce the friction associated with good habits. When friction is low, habits are easy.”
― James Clear</p>
</blockquote>

<hr>
<h2 id="should-you-build-your-own-workstation">
<a class="anchor" href="#should-you-build-your-own-workstation" aria-hidden="true"><span class="octicon octicon-link"></span></a>Should you build your own workstation?</h2>

<p>Due to my lack of experience with hardware components and having not built a PC till now, I was definitely nervous to build my own own rig without the help of people with experience. There are many dealers and companies that provide services of building  DL workstation either as a fixed option or also provide customizing your options.</p>

<p>Starting out, I was certain that this was the right choice considering that the parts are quite expensive and its natural to feel nervous that you might fry a component and thus waste loads of money. So, I started out researching all the components needed to build a decent DL workstation. Here again, I would like to point back to another Tim Dettmers blog, <a href="https://timdettmers.com/2018/12/16/deep-learning-hardware-guide/">A Full Hardware Guide to Deep Learning</a>, which shaped my though process in building Prometheus.</p>

<p>This was followed by endless hours of watching various PC builds on YouTube and learning more and more about the fascinating hobby of PC building. These hours spent watching people such jaw-dropping builds motiavted be so much in wanting to build my own PC and the more I saw, the less daunting the whole task seemed. I highly recommend watching builds based on the components you decide specifically by <a href="https://www.youtube.com/user/LinusTechTips">Linus Tech Tips</a>, <a href="https://www.youtube.com/user/Jayztwocents">Jays Two Cents</a> and <a href="https://www.youtube.com/user/AwesomeSauceNews">BitWit</a>.</p>

<p>If you would like an all-in-one resource to build a PC based on the components needed to build a DL worksation like mine, this is the only one you’ll probably need:
<a href="https://www.youtube.com/watch?v=IhX0fOUYd8Q">How to Build a PC! Step-by-step</a> by <a href="https://www.youtube.com/user/AwesomeSauceNews">BitWit</a>.</p>

<p>In hindsight, I can confidently say that building my own rig has been a wonderful learning experience that I am glad I did. Despite ones fears, it is worth pointing out that the process despite seeming pretty intimidating is quite easy if one follows the right guides. The components involved in building the PC are deinitely expensive and touted as quite delicate but in all fairness all the parts available today are quite rugged and one can dispel unnecessary fears of damaging them. Having built the entire system on my own, I have full control on any future expansion plans I have on this build and know exactly what the process is. I’m definitely another in the long line of individuals who would like to take PC building as a valuable hobby.</p>

<p>This being said, If you’re the type of person who doesn’t envy this process and don’t want to deal with the hassle of building your machine, I would suggest checking out <a href="https://www.ant-pc.com/ai-and-deep-learning">Ant-PC</a> who provide customizable builds specific to deep learning and also provide ons-site warranty and they thoroughly stress test their parts before shipping for an affordable premium cost in comparison.</p>

<hr>
<h2 id="components">
<a class="anchor" href="#components" aria-hidden="true"><span class="octicon octicon-link"></span></a>Components</h2>

<p><img src="https://drive.google.com/file/d/1bkc1p_opfoxYZnDC_kRzFk6OtWQCIYGI/view?usp=sharing" alt="components"></p>

<hr>
<h3 id="gpu">
<a class="anchor" href="#gpu" aria-hidden="true"><span class="octicon octicon-link"></span></a>GPU</h3>

<p>Arguably the most important component nowadays in a PC build, it is especially important for my use case since almost all the heavy lifting of training an ML model nowadays is done by it. It comprises of almost 50% of the overall cost of teh build and thus deciding this component is definitely one of the most importamt aspect to building any deep learning rig.</p>

<p>My insight into choosing the GPU is heavily shaped by Tim Dettmers blog <a href="https://timdettmers.com/2019/04/03/which-gpu-for-deep-learning/">post</a> where he compares the price to performance of the latest NVIDIA cards.</p>

<p>In the blog post which is a little dated today, he recommends the RTX 2070 as the sweet spot in terms of cost-efficiency and  performance. But since the release of the 20 series RTX Super cards which provide much better prefomance for mot much a difference, I opted for the RTX 2070 Super and specifically chose Gigabyte’s RTX 2070 Super Windforce OC, which is highly regarded as one of the best cost efficient GPU in the market today.</p>

<p>The recent NVIDIA cards since the 1080 Ti offer the possibility of training DL models at half-precision points i.e. allow the possibilty of training in FP16 over full precision training at FP32 which has been vital for training large models much quicker and lowering the GPU RAM usage since in theory this type of training doubles the GPU RAM at your disposal.</p>

<p>I would have loved to opt for the RTX 2080 Ti but in all honesty couldn’t fathom and justify the price difference between the two. I have developed my build in such a way that it can suport a multiple GPU system, so maybe down the road ;).</p>

<hr>
<h3 id="cpu-and-motherboard">
<a class="anchor" href="#cpu-and-motherboard" aria-hidden="true"><span class="octicon octicon-link"></span></a>CPU and Motherboard</h3>

<h3 id="ram">
<a class="anchor" href="#ram" aria-hidden="true"><span class="octicon octicon-link"></span></a>RAM</h3>

<p>RAM Clock Speed and RAM Latency</p>

<p>The memory timings are given through a series of numbers; for instance, 4-4-4-8, 5-5-5-15, 7-7-7-21, or 9-9-9-24. These numbers indicate the amount of clock cycles that it takes the memory to perform a certain operation. The smaller the number, the faster the memory.</p>

<h3 id="cpu-cooler">
<a class="anchor" href="#cpu-cooler" aria-hidden="true"><span class="octicon octicon-link"></span></a>CPU Cooler</h3>

<h3 id="storage">
<a class="anchor" href="#storage" aria-hidden="true"><span class="octicon octicon-link"></span></a>Storage</h3>

<h3 id="cabinet">
<a class="anchor" href="#cabinet" aria-hidden="true"><span class="octicon octicon-link"></span></a>Cabinet</h3>


  </div><a class="u-url" href="/through-tinted-lenses/hardware/setup/2020/06/19/Introducing-Prometheus,-my-very-own-deep-learning-arsenal.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/through-tinted-lenses/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/through-tinted-lenses/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/through-tinted-lenses/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>Immerse into the lesser known.</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/harish3110" title="harish3110"><svg class="svg-icon grey"><use xlink:href="/through-tinted-lenses/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://twitter.com/harish3110" title="harish3110"><svg class="svg-icon grey"><use xlink:href="/through-tinted-lenses/assets/minima-social-icons.svg#twitter"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
