---
toc: true
layout: post
description: 
categories: [workstation, hardware, setup]
title: Introducing Prometheus, my very own deep learning arsenal.

---
>“In Greek mythology, Prometheus, meaning “forethought” is a Titan, a culture hero, and a trickster figure who is credited with the creation of humanity from clay, and who defies the gods by stealing fire from Zeus and giving it to humanity. Prometheus is known for his intelligence and as a champion of humankind and also seen as the author of the human arts and sciences generally.”

![](https://miro.medium.com/max/547/1*1K9acuplyn85jwEN8itwXA.png "Prometheus")
![](https://miro.medium.com/max/700/1*1GjAMdcrdK-j-oFCG-AgbQ.jpeg "Prometheus Setup")

---

## Why own a Deep Learning workstation?

Today, there is a myriad of cloud GPU options one can use to dabble in the field of deep learning. Over the past year or so, I have used almost all the possible options available which have helped me grasp the concepts of the field as it has made it easy for anyone to prototype the knowledge acquired in the field at an affordable cost. Most of these services also offer free tier options and provide almost immediate access to a GPU instance.

My overall favorite has been Google’s GCP which also provides a 300$ credit to all their users as well as the newly launched Colab Pro which in my opinion is the best value for money option for most DL enthusiasts as it gives you access to multiple GPU instances for a nominal monthly fee. GCP’s main advantage is full command-line access to your Linux based server whereas Colab’s interface is quite intuitive as well. Until recently, I had opted for the Colab Pro for most of my prototyping work and finally renting a GCP instance to train large models on an hourly basis.

This being said, there are still downsides to this setup which becomes way too evident as you start spending long hours with a setup as mentioned above which I’m sure anyone in the field long enough can easily vouch for. Even though gaining access to a GPU instance has become way too easy, here the major frustration points which have bugged me long enough to shell out and invest in building my own DL rig:

- The setup process of getting your instance started with the correct requirements can be quite tedious and takes some time to get a hang of things in each cloud platform available.
- Preemptible instances, which are the free-tier option provided by cloud services can get annoying as you can be kicked off the instance abruptly in the middle of your training process.
- On the other hand, the constant worry to ensure shutting down your device to avoid racking up the bill is real.

In short, having your workstation at hand gives you the much-needed freedom to prototype models at the flick of your fingers and gets rid of all the friction involved in using the cloud options available. This is an extension to James Clear’s advice ‘make it easy’ which is basically to eliminate the friction involved in performing long-term rewarding habits.

>“Human behavior follows the Law of Least Effort. Reduce the friction associated with good habits. When friction is low, habits are easy.”
― James Clear
   
   
---

Happy learning, stay at home and stay safe! :)
